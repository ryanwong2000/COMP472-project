========================================
(A) Base-DT

(B) Confusion Matrix
[[135  50 154]
 [ 52 201  67]
 [157  63 166]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.392442  0.398230  0.395315
I   0.640127  0.628125  0.634069
M   0.428941  0.430052  0.429495

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.48038277511961724
Macro-Average F1 Score: 0.48629322017284
Weighted-Average F1 Score: 0.48105184066655154

========================================
(A) Top-DT {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 4}

(B) Confusion Matrix
[[  0  68 271]
 [  0 258  62]
 [  0  85 301]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.000000  0.000000  0.000000
I   0.627737  0.806250  0.705882
M   0.474763  0.779793  0.590196

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.5349282296650718
Macro-Average F1 Score: 0.43202614379084964
Weighted-Average F1 Score: 0.4341608030772117

========================================
(A) Base-MLP

(B) Confusion Matrix
[[  0  50 289]
 [  0 222  98]
 [  0  70 316]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.000000  0.000000  0.000000
I   0.649123  0.693750  0.670695
M   0.449502  0.818653  0.580349

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.5148325358851674
Macro-Average F1 Score: 0.417014602677882
Weighted-Average F1 Score: 0.41974837212803545

========================================
(A) Top-MLP {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[278  58   3]
 [ 46 268   6]
 [298  74  14]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.446945  0.820059  0.578564
I   0.670000  0.837500  0.744444
M   0.608696  0.036269  0.068460

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.5358851674641149
Macro-Average F1 Score: 0.46382269932794173
Weighted-Average F1 Score: 0.4409386073531605

========================================
ABALONE base_dt
	Average accuracy: 0.48038277511961724
	Variance accuracy: 0.0
	Average macro_average: 0.48629322017284
	Variance macro_average: 0.0
	Average weighted_average: 0.48105184066655154
	Variance weighted_average: 0.0
ABALONE top_dt
	Average accuracy: 0.5349282296650718
	Variance accuracy: 0.0
	Average macro_average: 0.43202614379084964
	Variance macro_average: 0.0
	Average weighted_average: 0.4341608030772117
	Variance weighted_average: 0.0
ABALONE base_mlp
	Average accuracy: 0.5148325358851674
	Variance accuracy: 0.0
	Average macro_average: 0.417014602677882
	Variance macro_average: 0.0
	Average weighted_average: 0.41974837212803545
	Variance weighted_average: 0.0
ABALONE top_mlp
	Average accuracy: 0.5358851674641149
	Variance accuracy: 0.0
	Average macro_average: 0.46382269932794173
	Variance macro_average: 0.0
	Average weighted_average: 0.4409386073531605
	Variance weighted_average: 0.0
========================================
(A) Base-DT

(B) Confusion Matrix
[[136  38 131]
 [ 42 217  81]
 [140  74 186]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.427673  0.445902  0.436597
I   0.659574  0.638235  0.648729
M   0.467337  0.465000  0.466165

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.5157894736842106
Macro-Average F1 Score: 0.5171639904079912
Weighted-Average F1 Score: 0.5169342546906954

========================================
(A) Top-DT {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 3}

(B) Confusion Matrix
[[131  34 140]
 [ 27 242  71]
 [128  65 207]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.458042  0.429508  0.443316
I   0.709677  0.711765  0.710720
M   0.495215  0.517500  0.506112

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.5550239234449761
Macro-Average F1 Score: 0.5533828041333343
Weighted-Average F1 Score: 0.5543551520882063

========================================
(A) Base-MLP

(B) Confusion Matrix
[[  0  35 270]
 [  0 225 115]
 [  0  78 322]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.000000  0.000000  0.000000
I   0.665680  0.661765  0.663717
M   0.455446  0.805000  0.581752

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.523444976076555
Macro-Average F1 Score: 0.4151564327836002
Weighted-Average F1 Score: 0.4386265172160409

========================================
(A) Top-MLP {'activation': 'tanh', 'hidden_layer_sizes': (10, 10, 10), 'solver': 'adam'}

(B) Confusion Matrix
[[162  75  68]
 [ 18 300  22]
 [177 109 114]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.453782  0.531148  0.489426
I   0.619835  0.882353  0.728155
M   0.558824  0.285000  0.377483

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.5511961722488038
Macro-Average F1 Score: 0.531688255129182
Weighted-Average F1 Score: 0.5242498731949506

========================================
ABALONE base_dt
	Average accuracy: 0.4980861244019139
	Variance accuracy: 0.0003134085758109939
	Average macro_average: 0.5017286052904156
	Variance macro_average: 0.0002382511137278747
	Average weighted_average: 0.4989930476786235
	Variance weighted_average: 0.00032188690905001936
ABALONE top_dt
	Average accuracy: 0.544976076555024
	Variance accuracy: 0.00010095922712392087
	Average macro_average: 0.49270447396209194
	Variance macro_average: 0.003681859752370297
	Average weighted_average: 0.494257977582709
	Variance weighted_average: 0.003611670383544193
ABALONE base_mlp
	Average accuracy: 0.5191387559808612
	Variance accuracy: 1.8543531512557235e-05
	Average macro_average: 0.4160855177307411
	Variance macro_average: 8.631988390037907e-07
	Average weighted_average: 0.4291874446720382
	Variance weighted_average: 8.909609049094606e-05
ABALONE top_mlp
	Average accuracy: 0.5435406698564593
	Variance accuracy: 5.8606716879191915e-05
	Average macro_average: 0.4977554772285619
	Variance macro_average: 0.0011514334160528158
	Average weighted_average: 0.48259424027405556
	Variance weighted_average: 0.001735191754040358
========================================
(A) Base-DT

(B) Confusion Matrix
[[125  49 133]
 [ 48 212  77]
 [155  71 175]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.381098  0.407166  0.393701
I   0.638554  0.629080  0.633782
M   0.454545  0.436409  0.445293

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.48995215311004786
Macro-Average F1 Score: 0.4909250573644406
Weighted-Average F1 Score: 0.4909214709174843

========================================
(A) Top-DT {'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 4}

(B) Confusion Matrix
[[153  38 116]
 [ 59 235  43]
 [185  61 155]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.385390  0.498371  0.434659
I   0.703593  0.697329  0.700447
M   0.493631  0.386534  0.433566

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.5196172248803828
Macro-Average F1 Score: 0.5228908727884137
Weighted-Average F1 Score: 0.5199532549378616

========================================
(A) Base-MLP

(B) Confusion Matrix
[[  0  29 278]
 [  0 223 114]
 [  0  63 338]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.000000  0.000000  0.000000
I   0.707937  0.661721  0.684049
M   0.463014  0.842893  0.597701

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.5368421052631579
Macro-Average F1 Score: 0.4272500763932962
Weighted-Average F1 Score: 0.4499547376046323

========================================
(A) Top-MLP {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[ 82  39 186]
 [ 13 264  60]
 [ 99  77 225]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.422680  0.267101  0.327345
I   0.694737  0.783383  0.736402
M   0.477707  0.561097  0.516055

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.5464114832535886
Macro-Average F1 Score: 0.5266006762976548
Weighted-Average F1 Score: 0.5316750692739443

========================================
ABALONE base_dt
	Average accuracy: 0.4953748006379586
	Variance accuracy: 0.0002236416036466406
	Average macro_average: 0.49812742264842397
	Variance macro_average: 0.00018477110866054738
	Average weighted_average: 0.4963025220915771
	Variance weighted_average: 0.0002290691285691157
ABALONE top_dt
	Average accuracy: 0.5365231259968103
	Variance accuracy: 0.0002102108976951589
	Average macro_average: 0.5027666069041992
	Variance macro_average: 0.0026570662069361445
	Average weighted_average: 0.5028230700344265
	Variance weighted_average: 0.0025545018731090658
ABALONE base_mlp
	Average accuracy: 0.5250398724082935
	Variance accuracy: 8.200870452192568e-05
	Average macro_average: 0.41980703728492613
	Variance macro_average: 2.8274881477032395e-05
	Average weighted_average: 0.43610987564956954
	Variance weighted_average: 0.00015523749493800252
ABALONE top_mlp
	Average accuracy: 0.5444976076555025
	Variance accuracy: 4.090260448860278e-05
	Average macro_average: 0.5073705435849262
	Variance macro_average: 0.0009525212794431215
	Average weighted_average: 0.49895451660735174
	Variance weighted_average: 0.0016921117860971976
========================================
(A) Base-DT

(B) Confusion Matrix
[[133  44 135]
 [ 51 214  78]
 [144  67 179]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.405488  0.426282  0.415625
I   0.658462  0.623907  0.640719
M   0.456633  0.458974  0.457801

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.5033492822966508
Macro-Average F1 Score: 0.5047146914610676
Weighted-Average F1 Score: 0.5052475278032146

========================================
(A) Top-DT {'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 4}

(B) Confusion Matrix
[[110  36 166]
 [ 33 258  52]
 [101  72 217]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.450820  0.352564  0.395683
I   0.704918  0.752187  0.727786
M   0.498851  0.556410  0.526061

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.5598086124401914
Macro-Average F1 Score: 0.5498432242794045
Weighted-Average F1 Score: 0.553346736093776

========================================
(A) Base-MLP

(B) Confusion Matrix
[[  0  29 283]
 [  0 228 115]
 [  0  70 320]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.000000  0.000000  0.000000
I   0.697248  0.664723  0.680597
M   0.445682  0.820513  0.577617

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.5244019138755981
Macro-Average F1 Score: 0.4194047811484096
Weighted-Average F1 Score: 0.43896223372454224

========================================
(A) Top-MLP {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[133  34 145]
 [ 21 267  55]
 [142  77 171]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.449324  0.426282  0.437500
I   0.706349  0.778426  0.740638
M   0.460916  0.438462  0.449409

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.5464114832535886
Macro-Average F1 Score: 0.5425155585242913
Weighted-Average F1 Score: 0.5414432701847334

========================================
ABALONE base_dt
	Average accuracy: 0.4973684210526316
	Variance accuracy: 0.00017965476980838388
	Average macro_average: 0.49977423985158487
	Variance macro_average: 0.0001467143521972908
	Average weighted_average: 0.4985387735194865
	Variance weighted_average: 0.00018680430777331692
ABALONE top_dt
	Average accuracy: 0.5423444976076556
	Variance accuracy: 0.000259323275566036
	Average macro_average: 0.5145357612480005
	Variance macro_average: 0.00240833863710676
	Average weighted_average: 0.5154539865492639
	Variance weighted_average: 0.0023944965608461745
ABALONE base_mlp
	Average accuracy: 0.5248803827751196
	Variance accuracy: 6.158283922071403e-05
	Average macro_average: 0.419706473250797
	Variance macro_average: 2.123650048265527e-05
	Average weighted_average: 0.4368229651683127
	Variance weighted_average: 0.000117953611188726
ABALONE top_mlp
	Average accuracy: 0.544976076555024
	Variance accuracy: 3.1363750829880147e-05
	Average macro_average: 0.5161567973197675
	Variance macro_average: 0.0009459857236613785
	Average weighted_average: 0.5095767050016972
	Variance weighted_average: 0.0016075764984277959
========================================
(A) Base-DT

(B) Confusion Matrix
[[141  40 134]
 [ 50 206  74]
 [159  62 179]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.402857  0.447619  0.424060
I   0.668831  0.624242  0.645768
M   0.462532  0.447500  0.454892

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.5033492822966508
Macro-Average F1 Score: 0.5082400567905725
Weighted-Average F1 Score: 0.5058748264222452

========================================
(A) Top-DT {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 3}

(B) Confusion Matrix
[[119  36 160]
 [ 29 250  51]
 [115  68 217]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.452471  0.377778  0.411765
I   0.706215  0.757576  0.730994
M   0.507009  0.542500  0.524155

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.5607655502392345
Macro-Average F1 Score: 0.5556378157670391
Weighted-Average F1 Score: 0.5555940557676287

========================================
(A) Base-MLP

(B) Confusion Matrix
[[  0  49 266]
 [  0 232  98]
 [  0  77 323]]

(C) Precision, Recall, F1 Score
   precision   recall  f1-score
F   0.000000  0.00000  0.000000
I   0.648045  0.70303  0.674419
M   0.470160  0.80750  0.594296

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.5311004784688995
Macro-Average F1 Score: 0.42290494426734554
Weighted-Average F1 Score: 0.44045610602414664

========================================
(A) Top-MLP {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[ 35  52 228]
 [  3 279  48]
 [ 39 100 261]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.454545  0.111111  0.178571
I   0.647332  0.845455  0.733246
M   0.486034  0.652500  0.557097

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.5502392344497608
Macro-Average F1 Score: 0.48963809211271897
Weighted-Average F1 Score: 0.49862195029228984

========================================
ABALONE base_dt
	Average accuracy: 0.49856459330143543
	Variance accuracy: 0.00014944712804194075
	Average macro_average: 0.5014674032393824
	Variance macro_average: 0.00012883869078894464
	Average weighted_average: 0.5000059841000383
	Variance weighted_average: 0.0001580542737693856
ABALONE top_dt
	Average accuracy: 0.5460287081339714
	Variance accuracy: 0.00026175224926169307
	Average macro_average: 0.5227561721518083
	Variance macro_average: 0.0021969715313951707
	Average weighted_average: 0.5234820003929368
	Variance weighted_average: 0.002173393273773757
ABALONE base_mlp
	Average accuracy: 0.5261244019138756
	Variance accuracy: 5.5456605846935925e-05
	Average macro_average: 0.42034616745410674
	Variance macro_average: 1.8626035081116374e-05
	Average weighted_average: 0.4375495933394795
	Variance weighted_average: 9.647484294751355e-05
ABALONE top_mlp
	Average accuracy: 0.5460287081339714
	Variance accuracy: 2.9523133627892973e-05
	Average macro_average: 0.5108530562783578
	Variance macro_average: 0.0008693072550664375
	Average weighted_average: 0.5073857540598157
	Variance weighted_average: 0.001305262262861162
========================================
(A) Base-DT

(B) Confusion Matrix
[[144  52 139]
 [ 47 228  67]
 [138  62 168]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.437690  0.429851  0.433735
I   0.666667  0.666667  0.666667
M   0.449198  0.456522  0.452830

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.5167464114832536
Macro-Average F1 Score: 0.5177439317016493
Weighted-Average F1 Score: 0.516691592586832

========================================
(A) Top-DT {'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 6}

(B) Confusion Matrix
[[103  30 202]
 [ 32 246  64]
 [ 90  64 214]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.457778  0.307463  0.367857
I   0.723529  0.719298  0.721408
M   0.445833  0.581522  0.504717

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.538755980861244
Macro-Average F1 Score: 0.5313272495408831
Weighted-Average F1 Score: 0.5317601909458182

========================================
(A) Base-MLP

(B) Confusion Matrix
[[  0  37 298]
 [  0 233 109]
 [  0  72 296]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.000000  0.000000  0.000000
I   0.681287  0.681287  0.681287
M   0.421053  0.804348  0.552754

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.5062200956937799
Macro-Average F1 Score: 0.4113469949383262
Weighted-Average F1 Score: 0.4176207005928368

========================================
(A) Top-MLP {'activation': 'tanh', 'hidden_layer_sizes': (10, 10, 10), 'solver': 'adam'}

(B) Confusion Matrix
[[ 70  35 230]
 [  7 263  72]
 [ 52  68 248]]

(C) Precision, Recall, F1 Score
   precision    recall  f1-score
F   0.542636  0.208955  0.301724
I   0.718579  0.769006  0.742938
M   0.450909  0.673913  0.540305

(D) Accuracy, Macro-Average F1 Score, Weighted-Average F1 Score
Accuracy: 0.5559808612440191
Macro-Average F1 Score: 0.5283223339772084
Weighted-Average F1 Score: 0.530138350218491

========================================
ABALONE base_dt
	Average accuracy: 0.5015948963317385
	Variance accuracy: 0.00017045295564560258
	Average macro_average: 0.5041801579830936
	Variance macro_average: 0.0001441607671550909
	Average weighted_average: 0.5027869188478372
	Variance weighted_average: 0.00017037988516539954
ABALONE top_dt
	Average accuracy: 0.5448165869218501
	Variance accuracy: 0.0002254730635491153
	Average macro_average: 0.5241846850499874
	Variance macro_average: 0.0018410128549972964
	Average weighted_average: 0.524861698818417
	Variance weighted_average: 0.0018206789002044943
ABALONE base_mlp
	Average accuracy: 0.5228070175438596
	Variance accuracy: 0.0001012390334979105
	Average macro_average: 0.4188463053681433
	Variance macro_average: 2.6769627285482967e-05
	Average weighted_average: 0.43422811121503907
	Variance weighted_average: 0.0001355569199711486
ABALONE top_mlp
	Average accuracy: 0.5476874003189793
	Variance accuracy: 3.8358910179610054e-05
	Average macro_average: 0.5137646025614996
	Variance macro_average: 0.0007668082213497479
	Average weighted_average: 0.5111778534195949
	Variance weighted_average: 0.0011596186401564912
